import streamlit as st
import requests
import json
from datetime import datetime
import os, re, html
import time
from collections import defaultdict
from streamlit_folium import st_folium
import folium
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from streamlit_lottie import st_lottie
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import pickle
import bs4                      # íŒŒì‹±.
from PIL import Image
from wordcloud import WordCloud

@st.cache_data
def load_lottiefile(filepath: str):
    """ë¡œì»¬ JSON íŒŒì¼ì—ì„œ Lottie ì• ë‹ˆë©”ì´ì…˜ ë¡œë“œ"""
    with open(filepath, "r", encoding="utf-8") as f:
        return json.load(f)

NAVER_LOCAL_URL = "https://openapi.naver.com/v1/search/local.json"
NAVER_BLOG_URL  = "https://openapi.naver.com/v1/search/blog.json"
NAVER_IMAGE_URL = "https://openapi.naver.com/v1/search/image.json"

@st.cache_data(ttl=300)
def get_lat_lon(address: str):
    geolocator = Nominatim(user_agent="streamlit-folium-demo", timeout=10)
    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

    location = geocode(
        address,
        exactly_one=True,
        country_codes="kr",
        language="ko",
    )

    if location:
        return location.latitude, location.longitude
    return None, None


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë§›ì§‘ ì¶”ì²œ Application",
    page_icon="ğŸ½ï¸",
    layout="wide"
)

# API í‚¤ ì„¤ì • ####################!!!!!!!!!!!!!!!!!!!!!!!!ê°œì¸ APIë„£ê¸°!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID","bAZehsWIFzpW3ZcTG1Hn")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET","YV3IWu8E6m")

try:
    if not NAVER_CLIENT_ID:
        NAVER_CLIENT_ID = st.secrets["naver"]["client_id"]
    if not NAVER_CLIENT_SECRET:
        NAVER_CLIENT_SECRET = st.secrets["naver"]["client_secret"]
except:
    pass

API_CONFIGURED = bool(NAVER_CLIENT_ID and NAVER_CLIENT_SECRET)

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
if 'current_page' not in st.session_state:
    st.session_state.current_page = 1

if 'current_search_query' not in st.session_state:
    st.session_state.current_search_query = ""

if 'current_results' not in st.session_state:
    st.session_state.current_results = []

if 'favorites' not in st.session_state:
    st.session_state.favorites = []

if 'search_key' not in st.session_state:
    st.session_state.search_key = []

if 'show_favorites' not in st.session_state:
    st.session_state.show_favorites = False

if 'current_tab' not in st.session_state:
    st.session_state.current_tab = 1

# ì£¼ìš” ë„ì‹œ ì„¸ë¶€ ì§€ì—­ ë°ì´í„°ë² ì´ìŠ¤
MAJOR_CITIES_SUBDIVISIONS = {
    # ëŒ€ì „
    "ëŒ€ì „": [
        "ìœ ì„±êµ¬", "ì„œêµ¬", "ë™êµ¬", "ì¤‘êµ¬", "ëŒ€ë•êµ¬",
        "ëŒ€ì „ì—­", "ì„œëŒ€ì „", "ìœ ì„±", "ë‘”ì‚°", "ì€í–‰ë™", "íƒ„ë°©ë™",
        "ê¶ë™", "ë„ë§ˆë™", "ìš©ë¬¸ë™", "ëŒ€í¥ë™", "ì„ í™”ë™",
        "ë…¸ì€ë™", "ê´€í‰ë™", "ìœ ì„±ì˜¨ì²œ", "ëŒ€ì „ì‹œì²­",
        "ì¶©ë‚¨ëŒ€", "ëŒ€ì „í„°ë¯¸ë„", "ì¤‘ì•™ë¡œ", "ì‹ íƒ„ì§„", "ëŒ€ë™",
        "ê°€ì–‘ë™", "ë³€ë™", "ëª©ë™"
    ],
    
    # ì„œìš¸ - ê°•ë‚¨/ì„œì´ˆ
    "ê°•ë‚¨": [
        "ê°•ë‚¨ì—­", "ì—­ì‚¼ì—­", "ì„ ë¦‰ì—­", "ì‚¼ì„±ì—­", "ì²­ë‹´ì—­", "ì••êµ¬ì •ì—­",
        "ì—­ì‚¼ë™", "ì‚¼ì„±ë™", "ì²­ë‹´ë™", "ë…¼í˜„ë™", "ì‹ ì‚¬ë™", "ì••êµ¬ì •ë™",
        "ë„ì‚°ê³µì›", "ê°•ë‚¨ëŒ€ë¡œ", "í…Œí—¤ë€ë¡œ", "ì‹ ì‚¬ë™ ê°€ë¡œìˆ˜ê¸¸", "ì²­ë‹´ë™ ëª…í’ˆê±°ë¦¬"
    ],
    "ì„œì´ˆ": [
        "ì„œì´ˆì—­", "êµëŒ€ì—­", "ê°•ë‚¨ì—­", "ì–‘ì¬ì—­", "ë‚¨ë¶€í„°ë¯¸ë„",
        "ì„œì´ˆë™", "ë°˜í¬ë™", "ì–‘ì¬ë™", "ì ì›ë™"
    ],
    
    # ì„œìš¸ - ê°•ì„œ/ë§ˆí¬
    "í™ëŒ€": [
        "í™ëŒ€ì…êµ¬ì—­", "ìƒìˆ˜ì—­", "í•©ì •ì—­", "ë§ì›ì—­",
        "í™ëŒ€ê±°ë¦¬", "í™ëŒ€ì•", "ì—°ë‚¨ë™", "ì„œêµë™", "ë™êµë™", "ì°½ì²œë™"
    ],
    "ì‹ ì´Œ": [
        "ì‹ ì´Œì—­", "ì´ëŒ€ì—­", "ì‹ ì´Œë¡œí„°ë¦¬", "ì—°ì„¸ëŒ€", "ì´í™”ì—¬ëŒ€"
    ],
    "ì—¬ì˜ë„": [
        "ì—¬ì˜ë„ì—­", "êµ­íšŒì˜ì‚¬ë‹¹ì—­", "ì—¬ì˜ë‚˜ë£¨ì—­", "IFCëª°", "ì—¬ì˜ë„ í•œê°•ê³µì›"
    ],
    
    # ì„œìš¸ - ê°•ë¶/ì¢…ë¡œ
    "ê°•ë¶": [
        "ë¯¸ì•„ì—­", "ìˆ˜ìœ ì—­", "ê°•ë¶êµ¬ì²­ì—­", "4.19ë¯¼ì£¼ë¬˜ì§€ì—­",
        "ìˆ˜ìœ ë¦¬", "ë¯¸ì•„ë™", "ë²ˆë™"
    ],
    "ì¢…ë¡œ": [
        "ì¢…ê°ì—­", "ê´‘í™”ë¬¸ì—­", "ì•ˆêµ­ì—­", "ì¢…ë¡œ3ê°€ì—­", "ì¢…ë¡œ5ê°€ì—­",
        "ì¸ì‚¬ë™", "ì‚¼ì²­ë™", "ë¶ì´Œ", "ì„œì´Œ", "ê´‘í™”ë¬¸"
    ],
    "ëª…ë™": [
        "ëª…ë™ì—­", "ì„ì§€ë¡œì…êµ¬ì—­", "íšŒí˜„ì—­", "ëª…ë™ê±°ë¦¬", "ë‚¨ëŒ€ë¬¸ì‹œì¥", "ì¤‘êµ¬ì²­"
    ],
    
    # ì„œìš¸ - ê°•ë™/ì†¡íŒŒ
    "ì ì‹¤": [
        "ì ì‹¤ì—­", "ì ì‹¤ìƒˆë‚´ì—­", "ì¢…í•©ìš´ë™ì¥ì—­", "ì„ì´Œì—­",
        "ë¡¯ë°ì›”ë“œ", "ì ì‹¤ìƒˆë‚´", "ì„ì´Œí˜¸ìˆ˜", "ì‹ ì²œë™"
    ],
    "ê°•ë™": [
        "ê°•ë™êµ¬ì²­ì—­", "ê¸¸ë™ì—­", "ë‘”ì´Œë™ì—­", "ëª…ì¼ì—­", "ê³ ë•ì—­",
        "ì²œí˜¸ë™", "ì„±ë‚´ë™", "ë‘”ì´Œë™", "ì•”ì‚¬ë™"
    ],
    
    # ì„œìš¸ - ê¸°íƒ€ ì£¼ìš” ì§€ì—­
    "ê±´ëŒ€": [
        "ê±´ëŒ€ì…êµ¬ì—­", "êµ¬ì˜ì—­", "ê´‘ì§„êµ¬ì²­ì—­", "ê±´êµ­ëŒ€í•™êµ", "ê±´ëŒ€ ë¡œë°ì˜¤ê±°ë¦¬"
    ],
    "ì´íƒœì›": [
        "ì´íƒœì›ì—­", "ë…¹ì‚¬í‰ì—­", "í•œë‚¨ì—­", "ì´íƒœì› ê±°ë¦¬", "ê²½ë¦¬ë‹¨ê¸¸", "í•´ë°©ì´Œ"
    ],
    "ì„±ìˆ˜": [
        "ì„±ìˆ˜ì—­", "ëšì„¬ì—­", "ì„±ìˆ˜ë™1ê°€", "ì„±ìˆ˜ë™2ê°€", "ì„œìš¸ìˆ²", "ì„±ìˆ˜ ì¹´í˜ê±°ë¦¬"
    ],
    
    # ë¶€ì‚°
    "ë¶€ì‚°": [
        "í•´ìš´ëŒ€", "ê´‘ì•ˆë¦¬", "ì„œë©´", "ë‚¨í¬ë™", "ìê°ˆì¹˜", "ì„¼í…€ì‹œí‹°",
        "í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥", "ê´‘ì•ˆë¦¬í•´ìˆ˜ìš•ì¥", "ì„œë©´ì—­", "ë¶€ì‚°ì—­",
        "ë‚¨í¬ì—­", "ìê°ˆì¹˜ì‹œì¥", "ë²¡ìŠ¤ì½”", "ì‹ ì„¸ê³„ë°±í™”ì ",
        "ë™ë˜", "ì˜¨ì²œì¥", "ì—°ì‚°ë™", "ë¶€ì‚°ëŒ€", "ê²½ì„±ëŒ€", "ì†¡ì •"
    ],
    
    # ëŒ€êµ¬
    "ëŒ€êµ¬": [
        "ë™ì„±ë¡œ", "ë°˜ì›”ë‹¹", "ìˆ˜ì„±êµ¬", "ì¤‘êµ¬", "ë‹¬ì„œêµ¬",
        "ë™ì„±ë¡œì—­", "ë°˜ì›”ë‹¹ì—­", "ì¤‘ì•™ë¡œì—­", "ëª…ë•ì—­",
        "ë™ëŒ€êµ¬ì—­", "ë²”ì–´ë™", "ìˆ˜ì„±ëª»", "ë‘ë¥˜ë™", "ì„±ì„œ",
        "ê²½ë¶ëŒ€", "ê³„ëª…ëŒ€", "ì¹ ì„±ì‹œì¥", "ì„œë¬¸ì‹œì¥"
    ],
    
    # ì¸ì²œ
    "ì¸ì²œ": [
        "êµ¬ì›”ë™", "ë¶€í‰", "ì†¡ë„", "ì£¼ì•ˆ", "ì¸ì²œì—­",
        "êµ¬ì›”ë™ì—­", "ë¶€í‰ì—­", "ë¶€í‰ì‹œì¥", "ì†¡ë„êµ­ì œë„ì‹œ",
        "ì£¼ì•ˆì—­", "ê°„ì„ë™", "ì‘ì „ë™", "ê³„ì–‘", "ê²€ë‹¨",
        "ì¸ì²œê³µí•­", "ì„ì™•ë¦¬", "ì›”ë¯¸ë„"
    ],
    
    # ê´‘ì£¼
    "ê´‘ì£¼": [
        "ì¶©ì¥ë¡œ", "ê¸ˆë‚¨ë¡œ", "ìƒë¬´ì§€êµ¬", "ì²¨ë‹¨", "ìˆ˜ì™„",
        "ê´‘ì£¼ì—­", "ê´‘ì£¼ì†¡ì •ì—­", "ê´‘ì²œë™", "ë´‰ì„ ë™",
        "ì „ë‚¨ëŒ€", "ì¡°ì„ ëŒ€", "ì–‘ë™ì‹œì¥", "ë§ë°”ìš°ì‹œì¥"
    ],
    
    # ìš¸ì‚°
    "ìš¸ì‚°": [
        "ì‚¼ì‚°ë™", "ì„±ë‚¨ë™", "ë‹¬ë™", "ì˜¥ë™", "ë¬´ê±°ë™",
        "ìš¸ì‚°ì—­", "íƒœí™”ê°•ì—­", "í˜„ëŒ€ë°±í™”ì ", "ë¡¯ë°ë°±í™”ì ",
        "ìš¸ì‚°ëŒ€", "ìš¸ì‚°ê³µí•­", "ì¼ì‚°í•´ìˆ˜ìš•ì¥"
    ],
    
    # ê²½ê¸° - ìˆ˜ì›
    "ìˆ˜ì›": [
        "ìˆ˜ì›ì—­", "ìˆ˜ì›ì‹œì²­ì—­", "ì˜í†µì—­", "ë§í¬ì—­", "ë§¤íƒ„ì—­",
        "ì¸ê³„ë™", "ì˜í†µ", "ê´‘êµ", "í–‰ê¶ë™", "ìˆ˜ì›í™”ì„±",
        "ì„±ê· ê´€ëŒ€", "ì•„ì£¼ëŒ€", "ìˆ˜ì›ì‹œì²­", "ë¡¯ë°ë°±í™”ì "
    ],
    
    # ê²½ê¸° - ì„±ë‚¨
    "ë¶„ë‹¹": [
        "ì„œí˜„ì—­", "ìˆ˜ë‚´ì—­", "ì •ìì—­", "ë¯¸ê¸ˆì—­", "ì˜¤ë¦¬ì—­",
        "ì•¼íƒ‘ì—­", "ëª¨ë€ì—­", "íŒêµì—­", "íŒêµí…Œí¬ë…¸ë°¸ë¦¬"
    ],
    
    # ê²½ê¸° - ê³ ì–‘
    "ì¼ì‚°": [
        "ì¼ì‚°ì—­", "ì£¼ì—½ì—­", "ì •ë°œì‚°ì—­", "ë§ˆë‘ì—­", "ë°±ì„ì—­",
        "ì¼ì‚°ë™êµ¬", "ì¼ì‚°ì„œêµ¬", "ë¼í˜ìŠ¤íƒ€", "ì›¨ìŠ¤í„´ë”"
    ],
    
    # ê²½ê¸° - ê¸°íƒ€
    "ì•ˆì–‘": [
        "ì•ˆì–‘ì—­", "í‰ì´Œì—­", "ë²”ê³„ì—­", "ì¸ë•ì›ì—­", "ì•ˆì–‘ì‹œì²­"
    ],
    "ë¶€ì²œ": [
        "ë¶€ì²œì—­", "ì¤‘ë™ì—­", "ìƒë™ì—­", "ë¶€ì²œì‹œì²­", "ë¶€ì²œí„°ë¯¸ë„"
    ],
}

#util í•¨ìˆ˜
def strip_tags(s: str) -> str:
    s = re.sub(r"<[^>]+>", "", s or "")
    return html.unescape(s)

def cut_to_dong(address: str) -> str:
    if not address:
        return ""

    m = re.search(r"^(.+?ë™)(?=\s|$)", address)
    return m.group(1) if m else address

def naver_headers():
    cid = NAVER_CLIENT_ID
    csec = NAVER_CLIENT_SECRET
    if not cid or not csec:
        raise RuntimeError("í™˜ê²½ë³€ìˆ˜ NAVER_CLIENT_ID / NAVER_CLIENT_SECRET ì„¤ì • í•„ìš”")
    return {"X-Naver-Client-Id": cid, "X-Naver-Client-Secret": csec}

@st.cache_data(ttl=300)
def naver_search(url, params):
    r = requests.get(url, headers=naver_headers(), params=params, timeout=10)
    r.raise_for_status()
    return r.json()

# ì§€ì—­ ì„¸ë¶„í™” í•¨ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
def generate_location_variations(base_location):
    """
    ì§€ì—­ë³„ ì„¸ë¶€ ê²€ìƒ‰ì–´ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
    
    1ë‹¨ê³„: ì£¼ìš” ë„ì‹œëŠ” ë¯¸ë¦¬ ì •ì˜ëœ ì„¸ë¶€ ì§€ì—­ ì‚¬ìš©
    2ë‹¨ê³„: ì—†ìœ¼ë©´ ê¸°ë³¸ ë³€í˜• íŒ¨í„´ ìƒì„±
    
    ë„¤ì´ë²„ APIì˜ 5ê°œ ì œí•œì„ ìš°íšŒí•˜ê¸° ìœ„í•´ ì§€ì—­ì„ ì„¸ë¶„í™”
    """
    base = base_location.lower().strip()
    variations = [base_location]
    
    # 1ë‹¨ê³„: ì£¼ìš” ë„ì‹œ ì„¸ë¶€ ì§€ì—­ í™•ì¸
    for city_key, subdivisions in MAJOR_CITIES_SUBDIVISIONS.items():
        if city_key.lower() in base or base in city_key.lower():
            variations.extend(subdivisions)
            return variations
    
    # 2ë‹¨ê³„: ì£¼ìš” ë„ì‹œê°€ ì•„ë‹ˆë©´ ê¸°ë³¸ ë³€í˜• íŒ¨í„´ ìƒì„±
    variations.extend([
        f"{base_location}ì—­",
        f"{base_location} ì‹œë‚´",
        f"{base_location} ì¤‘ì‹¬ê°€",
        f"{base_location} ë²ˆí™”ê°€",
        f"{base_location} êµ¬ë„ì‹¬",
        f"{base_location} ì‹ ë„ì‹¬",
        f"{base_location} í„°ë¯¸ë„",
        f"{base_location} ì‹œì²­"
    ])
    
    # 3ë‹¨ê³„: "êµ¬" ë‹¨ìœ„ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë™ ë‹¨ìœ„ë„ ì¶”ê°€
    if "êµ¬" in base_location:
        variations.extend([
            f"{base_location} 1ë™",
            f"{base_location} 2ë™",
            f"{base_location} 3ë™"
        ])
    
    return variations

# API í˜¸ì¶œ í•¨ìˆ˜
def fetch_restaurants_by_location(location, food_type="ì „ì²´", max_per_location=5, detail_type=False):
    """
    íŠ¹ì • ì§€ì—­ì˜ ë§›ì§‘ ì •ë³´ë¥¼ ê°€ì ¸ì˜´
    
    Parameters:
    - location: ê²€ìƒ‰í•  ì§€ì—­, í˜¹ì€ ìƒì„¸ ë§¤ì¥
    - food_type: ìŒì‹ ì¢…ë¥˜
    - max_per_location: í•´ë‹¹ ì§€ì—­ì—ì„œ ê°€ì ¸ì˜¬ ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸ 5ê°œ)
    - detail_type : í•œ ìŒì‹ì  ê²€ìƒ‰ì¼ ê²½ìš° True
    
    Returns:
    - ë§›ì§‘ ë¦¬ìŠ¤íŠ¸
    """
    if not API_CONFIGURED:
        return []
    
    url = NAVER_LOCAL_URL
    
    # ê²€ìƒ‰ì–´ ìƒì„±
    if detail_type :
        search_query = {location}
    elif food_type == "ì „ì²´":
        search_query = f"{location} ë§›ì§‘"
    else:
        search_query = f"{location} {food_type}"
    
    params = {
        "query": search_query,
        "display": max_per_location,
        "start": 1,
        "sort": "random"
    }
    
    try:
        response = requests.get(url, headers=naver_headers(), params=params, timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            items = data.get('items', [])
            
            # ê° í•­ëª©ì— ê²€ìƒ‰ëœ ì„¸ë¶€ ì§€ì—­ ì •ë³´ ì¶”ê°€
            for item in items:
                item['search_location'] = location
                #st.write(item['title'] + "ì¤‘ê°„ì²´í¬")
            
            return items
        elif response.status_code == 429:
            st.warning(f"âš ï¸ API í˜¸ì¶œ í•œë„ ë„ë‹¬: {location}")
            return []
        else:
            return []
            
    except Exception as e:
        return []

def is_address_match(address, road_address, base_location):
    """
    ì£¼ì†Œê°€ ê²€ìƒ‰í•œ ì§€ì—­ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
    
    Parameters:
    - address: ì§€ë²ˆ ì£¼ì†Œ
    - road_address: ë„ë¡œëª… ì£¼ì†Œ
    - base_location: ê²€ìƒ‰í•œ ê¸°ë³¸ ì§€ì—­ëª…
    
    Returns:
    - True: ì¼ì¹˜í•¨, False: ì¼ì¹˜í•˜ì§€ ì•ŠìŒ
    """
   
    # ëª¨ë“  ì£¼ì†Œ í•©ì¹˜ê¸°
    full_address = (address + " " + road_address).replace(" ", "").lower()
    base = base_location.replace(" ", "").lower()
    
    # ì£¼ìš” ë„ì‹œ íŠ¹ë³„ ì²˜ë¦¬
    city_mappings = {
        "ì„¸ì¢…": ["ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", "ì„¸ì¢…ì‹œ"],
        "ëŒ€ì „": ["ëŒ€ì „ê´‘ì—­ì‹œ", "ëŒ€ì „ì‹œ"],
        "ë¶€ì‚°": ["ë¶€ì‚°ê´‘ì—­ì‹œ", "ë¶€ì‚°ì‹œ"],
        "ëŒ€êµ¬": ["ëŒ€êµ¬ê´‘ì—­ì‹œ", "ëŒ€êµ¬ì‹œ"],
        "ì¸ì²œ": ["ì¸ì²œê´‘ì—­ì‹œ", "ì¸ì²œì‹œ"],
        "ê´‘ì£¼": ["ê´‘ì£¼ê´‘ì—­ì‹œ", "ê´‘ì£¼ì‹œ"],
        "ìš¸ì‚°": ["ìš¸ì‚°ê´‘ì—­ì‹œ", "ìš¸ì‚°ì‹œ"],
        "ê°•ë‚¨": ["ì„œìš¸íŠ¹ë³„ì‹œê°•ë‚¨êµ¬", "ì„œìš¸ê°•ë‚¨êµ¬"],
        "í™ëŒ€": ["ì„œìš¸íŠ¹ë³„ì‹œë§ˆí¬êµ¬", "ì„œìš¸ë§ˆí¬êµ¬"],
        "ì‹ ì´Œ": ["ì„œìš¸íŠ¹ë³„ì‹œì„œëŒ€ë¬¸êµ¬", "ì„œìš¸ì„œëŒ€ë¬¸êµ¬"],
        "ëª…ë™": ["ì„œìš¸íŠ¹ë³„ì‹œì¤‘êµ¬", "ì„œìš¸ì¤‘êµ¬"],
        "ê°•ë¶": ["ì„œìš¸íŠ¹ë³„ì‹œê°•ë¶êµ¬", "ì„œìš¸ê°•ë¶êµ¬"],
        "ì¢…ë¡œ": ["ì„œìš¸íŠ¹ë³„ì‹œì¢…ë¡œêµ¬", "ì„œìš¸ì¢…ë¡œêµ¬"],
        "ì ì‹¤": ["ì„œìš¸íŠ¹ë³„ì‹œì†¡íŒŒêµ¬", "ì„œìš¸ì†¡íŒŒêµ¬"],
        "ê±´ëŒ€": ["ì„œìš¸íŠ¹ë³„ì‹œê´‘ì§„êµ¬", "ì„œìš¸ê´‘ì§„êµ¬"],
        "ì´íƒœì›": ["ì„œìš¸íŠ¹ë³„ì‹œìš©ì‚°êµ¬", "ì„œìš¸ìš©ì‚°êµ¬"],
        "ì„±ìˆ˜": ["ì„œìš¸íŠ¹ë³„ì‹œì„±ë™êµ¬", "ì„œìš¸ì„±ë™êµ¬"],
        "ìˆ˜ì›": ["ê²½ê¸°ë„ìˆ˜ì›ì‹œ", "ìˆ˜ì›ì‹œ"],
        "ë¶„ë‹¹": ["ê²½ê¸°ë„ì„±ë‚¨ì‹œë¶„ë‹¹êµ¬", "ì„±ë‚¨ì‹œë¶„ë‹¹êµ¬"],
        "ì¼ì‚°": ["ê²½ê¸°ë„ê³ ì–‘ì‹œì¼ì‚°ë™êµ¬", "ê²½ê¸°ë„ê³ ì–‘ì‹œì¼ì‚°ì„œêµ¬", "ê³ ì–‘ì‹œì¼ì‚°"],
    }
    
    # ê²€ìƒ‰í•œ ì§€ì—­ì— ëŒ€í•œ ë§¤í•‘ì´ ìˆìœ¼ë©´ í™•ì¸
    if base in city_mappings:
        for city_name in city_mappings[base]:
            if city_name.replace(" ", "").lower() in full_address:
                return True
        return False
    
    # ê¸°ë³¸: ê²€ìƒ‰ì–´ê°€ ì£¼ì†Œì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    return base in full_address

def detail_search_restaurants(search_key, target_count=50):
    # ì¦ê²¨ì°¾ê¸° - íƒ€ê²Ÿ ë§¤ì¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    st.write(search_key)
    items = fetch_restaurants_by_location(location = search_key, max_per_location=5, detail_type=True)
    return items

def fetch_all_restaurants_with_variations(base_location, food_type, target_count=50):
    """
    ì§€ì—­ ë³€í˜•ì„ í™œìš©í•˜ì—¬ ë” ë§ì€ ë§›ì§‘ ì •ë³´ë¥¼ ìˆ˜ì§‘
    
    Parameters:
    - base_location: ê¸°ë³¸ ì§€ì—­ëª…
    - food_type: ìŒì‹ ì¢…ë¥˜
    - target_count: ëª©í‘œ ìˆ˜ì§‘ ê°œìˆ˜
    
    Returns:
    - ìˆ˜ì§‘ëœ ì „ì²´ ë§›ì§‘ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°ë¨)
    """
   
    # ì§€ì—­ ì„¸ë¶„í™”
    location_variations = generate_location_variations(base_location)
    
    all_items = []
    seen_ids = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ID ì„¸íŠ¸
    
    # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ìƒì„±
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, location in enumerate(location_variations):
        
        # í”„ë¡œê·¸ë ˆìŠ¤ ì—…ë°ì´íŠ¸
        progress = (idx + 1) / len(location_variations)
        progress_bar.progress(progress)
        status_text.text("ğŸ” Searching ...")
        
        # í•´ë‹¹ ì§€ì—­ì˜ ë§›ì§‘ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        items = fetch_restaurants_by_location(location, food_type, max_per_location=5)
        
        # ì¤‘ë³µ ì œê±° ë° ì§€ì—­ í•„í„°ë§í•˜ë©´ì„œ ì¶”ê°€
        for item in items:
           
           # IDë¡œ ì¤‘ë³µ ì²´í¬ (title + address ì¡°í•©)
            item_id = f"{item.get('title', '')}_{item.get('address', '')}"
            
            if item_id not in seen_ids:
                
                # ì£¼ì†Œ í•„í„°ë§
                address = item.get('address', '')
                road_address = item.get('roadAddress', '')
                
                # ì£¼ì†Œê°€ ê²€ìƒ‰ ì§€ì—­ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                if is_address_match(address, road_address, base_location):
                    seen_ids.add(item_id)
                    all_items.append(item)
        
        # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
        if len(all_items) >= target_count:
            break
        
        # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
        time.sleep(0.15)
    
    progress_bar.empty()
    status_text.empty()
    
    return all_items


# í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì •ì œí•´ ì£¼ëŠ” í•¨ìˆ˜.
# ì£¼ë¡œ ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•œë‹¤.
@st.cache_data
def cleanText(text):
    text = re.sub(r'\d|[a-zA-Z]|\W',' ', text)   # ìˆ˜ì¹˜, ì•ŒíŒŒë²³, íŠ¹ìˆ˜ë¬¸ì ì œê±°.
    text = re.sub(r'\s+',' ', text)              # ì‰ì—¬ ê³µë°± 1ê°œë¡œ ì¤„ì„.
    return text

# ì‚¬ì „ íŠ¸ë ˆì´ë‹ëœ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜.
@st.cache_resource
def getTokenizer():
    f = open('./resources/my_tokenizer1.model','rb')
    tokenizer = pickle.load(f)
    f.close()
    return tokenizer

# í† í°í™”ëœ í…ìŠ¤íŠ¸ë¥¼ ë„ìˆ˜í‘œë¡œ ì •ë¦¬í•´ì„œ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜í•´ ì£¼ëŠ” í•¨ìˆ˜.
def makeTable(tokens, nmin=2, nmax=5, ncut=1):
    tokens_new = []
    # ì¡°ê±´ì— ë§ëŠ” í† í°ë§Œ ê°€ì ¸ì˜´.
    for token in tokens:
        if len(token) >= nmin and len(token) <= nmax:         
            tokens_new.append(token)
    # Pandas ì‹œë¦¬ì¦ˆë¡œ í…Œì´ë¸”í™”.
    ser = pd.Series(tokens_new)
    ser = ser.value_counts()
    ser = ser[ser >= ncut]                          # ìµœì†Œ íšŸìˆ˜ ì´ìƒë§Œ.
    return dict(ser.sort_values(ascending=False))   # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•´ì„œ ë°˜í™˜.

# ì›Œë“œ í´ë¼ìš°ë“œ ì‹œê°í™” í•¨ìˆ˜.
def plotChart(count_dict, max_words_, container):
    img = Image.open('./resources/background_1.png')                    # íƒ€ì›í˜•.
    my_mask=np.array(img)  
    # ì›Œë“œ í´ë¼ìš°ë“œ ê°ì²´.
    wc = WordCloud(font_path='./resources/NanumSquareR.ttf',                # í•œê¸€ê¸€ê¼´ íŒŒì¼ ê²½ë¡œ.
                    background_color='white',
                    contour_color='grey',
                    contour_width=3,
                    max_words=max_words_,
                    mask=my_mask)   
    
    # í† í° (ë‹¨ì–´)ì˜ ë„ìˆ˜í‘œ (dict)ë¥¼ ì‚¬ìš©í•´ì„œ ìƒì„±.
    wc.generate_from_frequencies(count_dict)
    fig = plt.figure(figsize=(10,10))

    # st.write("wc type:", type(wc))
    # st.write("dict empty?:", not bool(count_dict))

    plt.imshow(wc.to_array(), interpolation='bilinear')
    #plt.imshow(wc, interpolation='bilinear')
    plt.axis("off")                                                         # ê°€ë¡œ/ì„¸ë¡œ ì¶•ì„ êº¼ì¤Œ.
    container.pyplot(fig)

# UI êµ¬ì„± ì‹œì‘

col1, col2 = st.columns([0.8, 8], gap="small")
with col1:
    # Lottie ì• ë‹ˆë©”ì´ì…˜ FILE (ìŒì‹ ê´€ë ¨ ì• ë‹ˆë©”ì´ì…˜)
    lottie_food = load_lottiefile("animation.json")
    if lottie_food:
        st_lottie(lottie_food, height=150, key="food_animation")
with col2:
    st.markdown("<h1 style='margin-top: 25px; margin-left: -10px;'>ì§€ì—­ë³„ ë§›ì§‘ ì¶”ì²œ</h1>", unsafe_allow_html=True)

st.markdown("---")

# ì‚¬ì´ë“œë°” - ê²€ìƒ‰ ì˜µì…˜
with st.sidebar:
    st.header("ğŸ” ê²€ìƒ‰")
    
    # ì§€ì—­ ì…ë ¥
    location = st.text_input(
        "ğŸ“ ì§€ì—­ ì…ë ¥", 
        placeholder="ì˜ˆ: ëŒ€ì „, ê°•ë‚¨, í™ëŒ€, ë¶€ì‚°",
        help="ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì§€ì—­ì„ ì…ë ¥í•˜ì„¸ìš”."
    )
    
    # ì¹´í…Œê³ ë¦¬ ì„ íƒ
    food_type = st.selectbox(
        "ğŸ´ ì¹´í…Œê³ ë¦¬",
        ["ì „ì²´", "í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹", "ì¹´í˜", "ë””ì €íŠ¸", "ë¶„ì‹", "ì¹˜í‚¨", "í”¼ì", "ê³ ê¸°", "íšŒ/í•´ì‚°ë¬¼"],
        help="ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”."
    )
    
    # ê²€ìƒ‰ ë²„íŠ¼
    search_button = st.button("ğŸ” Search", type="primary", use_container_width=True)
    if search_button:
        st.session_state.current_tab = 1

    st.markdown("---")
    
    # ì €ì¥ ëª©ë¡
    st.subheader("ğŸ’– ì €ì¥ ëª©ë¡")
    if st.session_state.favorites:
        
        # ì €ì¥í•œ ë§›ì§‘ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
        for idx, fav in enumerate(st.session_state.favorites, start=1):
            col1, col2, col3 = st.columns([4, 1, 1])
            with col1:
                st.write(f"{idx}. {fav['title'].replace('<b>', '').replace('</b>', '')}")
            with col2:
                if st.button("ğŸ”", key=f"search_{idx}", use_container_width=True):
                    st.session_state.search_key = st.session_state.favorites[idx-1]
                    st.session_state.current_tab = 2
            with col3:
                if st.button("X", key=f"remove_{idx}", use_container_width=True):
                    st.session_state.favorites.pop(idx-1)
                    st.rerun()
        if st.button("ğŸ—‘ï¸ Delete", use_container_width=True):
            st.session_state.favorites = []
            st.success("ì €ì¥ ëª©ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    else:
        st.write("ì•„ì§ ì €ì¥í•œ ë§›ì§‘ì´ ì—†ìŠµë‹ˆë‹¤.")

# ë©”ì¸ ì»¨í…ì¸  ì˜ì—­
def display_restaurant(item, index):
    """
    ë§›ì§‘ ì •ë³´ë¥¼ í™”ë©´ì— í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
    """
    # ì €ì¥ ì—¬ë¶€ í™•ì¸
    item_id = f"{item.get('title', '')}_{item.get('address', '')}"
    is_favorited = item_id in [f"{fav.get('title', '')}_{fav.get('address', '')}" for fav in st.session_state.favorites]
    
    with st.container():
        col_title, col_location, col_favorite = st.columns([2.5, 1, 0.5])
        
        with col_title:
            #st.markdown(f"### {index}. {item['title'].replace('<b>', '').replace('</b>', '')}")
            # ì œëª© í´ë¦­ì‹œ -> ìƒì„¸ ê²€ìƒ‰ í˜ì´ì§€ë¡œ ë„˜ì–´ê°€ë„ë¡
            if st.button(f"{index}. {item['title'].replace('<b>', '').replace('</b>', '')}", key=f"title_btn_{index}") :
                st.session_state.search_key = item
                st.session_state.current_tab = 2
                st.rerun()

        with col_location:
            if 'search_location' in item:
                st.markdown(f"<div style='text-align: right; color: #666; font-size: 0.9em;'>ğŸ” {item['search_location']}</div>", unsafe_allow_html=True)
        
        with col_favorite:
           
            # ì €ì¥ ë²„íŠ¼
            if is_favorited:
                if st.button("ğŸ’–", key=f"unfav_{index}", help="ì €ì¥ ì·¨ì†Œ"):
                    st.session_state.favorites = [fav for fav in st.session_state.favorites 
                                                   if f"{fav.get('title', '')}_{fav.get('address', '')}" != item_id]
                    st.rerun()
            else:
                if st.button("ğŸ¤", key=f"fav_{index}", help="ì €ì¥í•˜ê¸°"):
                    st.session_state.favorites.append(item)
                    st.rerun()
        
        info_col1, info_col2, info_col3 = st.columns([2, 1, 2])
        
        with info_col1:
            st.markdown(f"**ğŸ·ï¸ ì¹´í…Œê³ ë¦¬:** {item.get('category', 'ì •ë³´ ì—†ìŒ')}")
            st.markdown(f"**ğŸ“ ì£¼ì†Œ:** {item.get('roadAddress', item.get('address', 'ì •ë³´ ì—†ìŒ'))}")
        
        with info_col2:
            if item.get('link'):
                st.markdown(f"**ğŸ”— [link]({item['link']})**")

        with info_col3:
            pass
            address = item.get('roadAddress') or item.get('address')
            place_name = item.get('title', '').replace('<b>', '').replace('</b>', '')

            if address:
                lat, lon = get_lat_lon(address)

                if lat is not None and lon is not None:
                    m = folium.Map(location=[lat, lon], zoom_start=16)

                    folium.Marker(
                    [lat, lon],
                    popup=place_name,
                    tooltip=place_name
                    ).add_to(m)

                    st_folium(m, width=320, height=220)
                else:             
                    st.caption("ğŸ“ ìœ„ì¹˜ ì •ë³´ ì—†ìŒ")
            else:
                st.caption("ğŸ“ ì£¼ì†Œ ì—†ìŒ")       
        st.markdown("---")

# ìƒì„¸ì •ë³´ ì»¨í…ì¸  í•¨ìˆ˜ 
def detail_view_restaurants(items):
    #st.write(items)
    # ê° í•­ëª©ì— ê²€ìƒ‰ëœ ì„¸ë¶€ ì§€ì—­ ì •ë³´ ì¶”ê°€
    for item in items:
        #item['search_location'] = location
        #st.write(item['title'] + "ë“¤ì–´ì™”ë‹¤ detail_view_restaurants!")
        # # ëŒ€í‘œ ì´ë¯¸ì§€ 1ì¥
        img_data = naver_search(NAVER_IMAGE_URL, {"query": search_key, "display": 3, "start": 1, "sort": "sim"})
        img_items = img_data.get("items", [])
        
        # í›„ê¸°(ë¸”ë¡œê·¸) ì—¬ëŸ¬ ê°œ
        blog_q = f"{search_key} í›„ê¸°"
        blog_data = naver_search(NAVER_BLOG_URL, {"query": blog_q, "display": 3, "start": 1, "sort": "sim"})
        blog_items = blog_data.get("items", [])

        cols = st.columns(3)
        for i, it in enumerate(blog_items[:3]):
            with cols[i % 3]:
                with st.container(border=True):
                    # ì´ë¯¸ì§€ ë¨¼ì €
                    if img_items:
                        thumb = img_items[i].get("link") or img_items[i].get("thumbnail")
                        if thumb:
                            st.image(thumb, use_container_width=True)

                    # í›„ê¸° ë‚´ìš©
                    title = strip_tags(it.get("title",""))
                    desc  = strip_tags(it.get("description",""))
                    link  = it.get("link","")

                    st.markdown(f"**{title}**")
                    st.write(desc[:150] + ("..." if len(desc) > 150 else ""))
                    if link:
                        st.link_button("í›„ê¸° ì—´ê¸°", link)

# current_tab = 1
if st.session_state.current_tab == 1:
    title_name = f'{location} ì§€ì—­ '
    if food_type:
        title_name += f'{food_type} ì¹´í…Œê³ ë¦¬'
    st.subheader(f'{title_name}ê²€ìƒ‰ ê²°ê³¼ ì…ë‹ˆë‹¤.')
    # st.image('https://static.streamlit.io/examples/cat.jpg')
    
    # ê²€ìƒ‰ ë²„íŠ¼ì´ í´ë¦­ë˜ì—ˆì„ ë•Œ
    if search_button:
        if not API_CONFIGURED:
            st.error("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif not location:
            st.warning("âš ï¸ ì§€ì—­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            # ê²€ìƒ‰ ì‹¤í–‰
            target_count = 50  # ê³ ì •ê°’ìœ¼ë¡œ ì„¤ì •
            all_items = fetch_all_restaurants_with_variations(location, food_type, target_count)
            
            if all_items:
            
                # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
                st.session_state.current_results = all_items
                st.session_state.current_search_query = f"{location} {food_type}"
                st.session_state.current_page = 1  # ìƒˆ ê²€ìƒ‰ ì‹œ 1í˜ì´ì§€ë¡œ ë¦¬ì…‹
            else:
                st.warning("ğŸ˜¢ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§€ì—­ì´ë‚˜ ìŒì‹ ì¢…ë¥˜ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")



    # ì €ì¥ëœ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if st.session_state.current_results:
        all_items = st.session_state.current_results
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ì„¤ì •
        ITEMS_PER_PAGE = 10
        total_items = len(all_items)
        total_pages = (total_items + ITEMS_PER_PAGE - 1) // ITEMS_PER_PAGE
        
        # í˜„ì¬ í˜ì´ì§€ì— í‘œì‹œí•  í•­ëª© ê³„ì‚°
        start_idx = (st.session_state.current_page - 1) * ITEMS_PER_PAGE
        end_idx = min(start_idx + ITEMS_PER_PAGE, total_items)
        display_items = all_items[start_idx:end_idx]
        
        # ê²€ìƒ‰ ê²°ê³¼ í—¤ë”
        st.success(f"âœ… ì´ {total_items}ê°œì˜ ë§›ì§‘ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        st.markdown("---")
        
        # ê° ë§›ì§‘ ì •ë³´ í‘œì‹œ
        for idx, item in enumerate(display_items, start=start_idx + 1):
            display_restaurant(item, idx)
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ë²„íŠ¼
        if total_pages > 1:
            st.markdown("---")
            col1, col2, col3, col4, col5 = st.columns([1, 1, 2, 1, 1])
            
            with col1:
                if st.button("â®ï¸ ì²˜ìŒ", disabled=(st.session_state.current_page == 1), key="first_page"):
                    st.session_state.current_page = 1
                    st.rerun()
            
            with col2:
                if st.button("â—€ï¸ ì´ì „", disabled=(st.session_state.current_page == 1), key="prev_page"):
                    st.session_state.current_page -= 1
                    st.rerun()
            
            with col3:
                st.markdown(f"<div style='text-align: center; padding: 8px;'><b>{st.session_state.current_page} / {total_pages}</b></div>", unsafe_allow_html=True)
            
            with col4:
                if st.button("ë‹¤ìŒ â–¶ï¸", disabled=(st.session_state.current_page == total_pages), key="next_page"):
                    st.session_state.current_page += 1
                    st.rerun()
            
            with col5:
                if st.button("ë§ˆì§€ë§‰ â­ï¸", disabled=(st.session_state.current_page == total_pages), key="last_page"):
                    st.session_state.current_page = total_pages
                    st.rerun()
else: # current_tab = 2
    # ì¦ê²¨ì°¾ê¸° ê²€ìƒ‰ ë²„íŠ¼ì´ í´ë¦­ë˜ì—ˆì„ ë•Œ 
    if st.session_state.search_key:
        search_key = st.session_state.search_key.get('title', '').replace('<b>', '').replace('</b>', '') + ("_") + st.session_state.search_key.get('address', '').replace('<b>', '').replace('</b>', '')
        title_name = st.session_state.search_key.get('title', '').replace('<b>', '').replace('</b>', '')
        st.subheader(f'{title_name} ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ ì…ë‹ˆë‹¤.')
    
        address = st.session_state.search_key.get('address', '').replace('<b>', '').replace('</b>', '')
        items = detail_search_restaurants(search_key, target_count=50)

        # ì£¼ì†Œê¹Œì§€ í¬í•¨ëœ ì£¼ì†Œë¡œ ìƒì„¸ ê²€ìƒ‰ ì‹œë„
        if items : 
            pass
        # ì£¼ì†Œì— ë™ì´ í¬í•¨ëœ ê²½ìš° 2ì°¨ ê²€ìƒ‰ ì‹œë„
        elif 'ë™' in address :
            address = cut_to_dong(address)
            search_key = title_name + (" ") + address
            items = detail_search_restaurants(search_key, target_count=50)
        # ë™ì´ ë¯¸í¬í•¨ëœ ê²½ìš° titleë§Œìœ¼ë¡œ ì¬ê²€ìƒ‰ ìˆ˜í–‰
        else :
            search_key = st.session_state.search_key.get('title', '').replace('<b>', '').replace('</b>', '')
            items = detail_search_restaurants(search_key, target_count=50)

        if items:
            # 1. ë¸”ë¡œê·¸ ì¹´ë“œí˜• ë…¸ì¶œ
            detail_view_restaurants(items)

            # 2. ë¸”ë¡œê·¸ ì„¸ ê°œ í¬ë¡¤ë§
            corpus = ''
            blog_data = naver_search(NAVER_BLOG_URL, {"query": f"{search_key} í›„ê¸°", "display": 3, "start": 1, "sort": "sim"})
            blog_items = blog_data.get("items", [])

            # í•œê°œì”© ì§ì ‘ ë“¤ì–´ê°€ì„œ í¬ë¡¤ë§í•´ì„œ ê°€ì ¸ì˜¨ë‹¤.
            for item in blog_items:
                news_url = item['link']

                res = requests.get(news_url, headers={'User-Agent':'Mozilla'})    # í—¤ë”ì— User-Agent ì •ë³´ë¥¼ ë„£ì–´ì„œ ì°¨ë‹¨ì„ í”¼í•œë‹¤.
                soup = bs4.BeautifulSoup(res.text, 'html.parser')           # íŒŒì‹± ì§„í–‰.
                posts = soup.select("ul.lst_view > li.bx")
                iframe = soup.select_one("iframe#mainFrame")
                if iframe:
                    real_url = "https://blog.naver.com" + iframe.get("src")
                else:
                    real_url = news_url

                res2 = requests.get(real_url, headers={'User-Agent':'Mozilla/5.0'})
                soup2 = bs4.BeautifulSoup(res2.text, 'html.parser')

                content = soup2.select_one("div.se-main-container")
                if not content:
                    content = soup2.select_one("#postViewArea")

                if content:
                    text = content.get_text(" ", strip=True)
                    corpus += text

                # ì›Œë“œ í´ë¼ìš°ë“œ ì°¨íŠ¸ê°€ ì¶œë ¥ë  ìœ„ì¹˜.
                chart_container = st.empty()
                
            # ì¶©ë¶„í•œ ë°ì´í„°ê°€ í™•ë³´ë˜ì—ˆìœ¼ë©´, ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê³  ì‹œê°í™”ë¥¼ ì¶œë ¥í•œë‹¤.
            if len(corpus) > 100:                                               # ë§ë­‰ì¹˜ì— ìµœì†Œ 100ê°œ ì´ìƒì˜ ë¬¸ìê°€ ë“¤ì–´ìˆëŠ” ê²½ìš°.
                chart_container.info(':red[ì´ë¯¸ì§€ ìƒì„± ì¤‘...]')
                corpus = cleanText(corpus)
                my_tokenizer = getTokenizer()
                # tokens = my_tokenizer.tokenize(corpus, flatten=True)          # ì™¼ìª½ + ì˜¤ë¥¸ìª½ í† í°.
                tokens = [t1 for t1, t2 in my_tokenizer.tokenize(corpus, flatten=False)] # ì™¼ìª½ í† í° only!
                count_dict = makeTable(tokens)
                plotChart(count_dict, 70, chart_container)
            else:
                chart_container.error(':red[ë¸”ë¡œê·¸ ë°ì´í„° ë¶ˆì¶©ë¶„!]')

# í‘¸í„°
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
    <p>ë³¸ ì„œë¹„ìŠ¤ëŠ” ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ í™œìš©í•©ë‹ˆë‹¤.</p>
    </div>
    """,
    unsafe_allow_html=True
)